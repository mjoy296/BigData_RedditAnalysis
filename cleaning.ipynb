{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-76-132.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"final_cleaning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in full dataset \n",
    "df = spark.read.parquet(\"s3://ppol567lab2/sample.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sql table\n",
    "df.createOrReplaceTempView('sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- author_created_utc: long (nullable = true)\n",
      " |-- author_flair_background_color: string (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_richtext: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- a: string (nullable = true)\n",
      " |    |    |-- e: string (nullable = true)\n",
      " |    |    |-- t: string (nullable = true)\n",
      " |    |    |-- u: string (nullable = true)\n",
      " |-- author_flair_template_id: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- author_flair_text_color: string (nullable = true)\n",
      " |-- author_flair_type: string (nullable = true)\n",
      " |-- author_fullname: string (nullable = true)\n",
      " |-- author_patreon_flair: boolean (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- can_mod_post: boolean (nullable = true)\n",
      " |-- collapsed: boolean (nullable = true)\n",
      " |-- collapsed_reason: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created_utc: long (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- gildings: struct (nullable = true)\n",
      " |    |-- gid_1: long (nullable = true)\n",
      " |    |-- gid_2: long (nullable = true)\n",
      " |    |-- gid_3: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- is_submitter: boolean (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- no_follow: boolean (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- permalink: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- send_replies: boolean (nullable = true)\n",
      " |-- stickied: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |-- subreddit_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|              author|   count|\n",
      "+--------------------+--------+\n",
      "|           [deleted]|42737313|\n",
      "|       AutoModerator| 5222586|\n",
      "|    MemeInvestor_bot|  307896|\n",
      "|         transcribot|  269443|\n",
      "|KeepingDankMemesDank|  222801|\n",
      "|transcribersofreddit|  198197|\n",
      "| NFCAAOfficialRefBot|  136902|\n",
      "|      MTGCardFetcher|  130178|\n",
      "|          vokoxazara|  126528|\n",
      "|       imguralbumbot|  114199|\n",
      "|          mediapedia|   99348|\n",
      "|CommonMisspellingBot|   92196|\n",
      "|      TotesMessenger|   87903|\n",
      "|         Marketron-I|   87577|\n",
      "|        SnapshillBot|   72432|\n",
      "|          GVHFYTRTGH|   70857|\n",
      "|        sneakpeekbot|   70822|\n",
      "|           ManyYoung|   67701|\n",
      "|         WikiTextBot|   61143|\n",
      "|         request_bot|   60551|\n",
      "+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at author var\n",
    "spark.sql('select author, count(author) as count from sample group by author order by count(author) desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|author_cakeday|  count|\n",
      "+--------------+-------+\n",
      "|          true|1549258|\n",
      "|          null|      0|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at author cakeday var\n",
    "spark.sql('''select author_cakeday, count(author_cakeday) as count\n",
    "              from sample group by author_cakeday order by count(author_cakeday) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "|author_created_utc|  count|\n",
      "+------------------+-------+\n",
      "|        1325741068|5222586|\n",
      "|        1526661437| 307896|\n",
      "|        1493750700| 269443|\n",
      "|        1520156308| 222801|\n",
      "|        1490755650| 198197|\n",
      "|        1518056507| 136937|\n",
      "|        1396612931| 130178|\n",
      "|        1523799924| 126528|\n",
      "|        1494883468| 114199|\n",
      "|        1541446109|  99349|\n",
      "|        1488799491|  92196|\n",
      "|        1421289506|  87903|\n",
      "|        1534983431|  87578|\n",
      "|        1420513678|  72432|\n",
      "|        1537269564|  70857|\n",
      "|        1483196915|  70822|\n",
      "|        1542552946|  67701|\n",
      "|        1496576979|  61143|\n",
      "|        1341185839|  60551|\n",
      "|        1495052127|  59992|\n",
      "+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at author created var\n",
    "spark.sql('''select author_created_utc, count(author_created_utc) as count \n",
    "            from sample group by author_created_utc order by count(author_created_utc) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|author_flair_type|    count|\n",
      "+-----------------+---------+\n",
      "|             text|384650632|\n",
      "|         richtext| 48871799|\n",
      "|             null|        0|\n",
      "+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at author flair type var\n",
    "\n",
    "spark.sql('''select author_flair_type, count(author_flair_type) as count \n",
    "            from sample group by author_flair_type order by count(author_flair_type) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|author_patreon_flair|    count|\n",
      "+--------------------+---------+\n",
      "|               false|427232451|\n",
      "|                true|    14254|\n",
      "|                null|        0|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at author patreon falir var\n",
    "\n",
    "spark.sql('''select author_patreon_flair, count(author_patreon_flair) as count \n",
    "            from sample group by author_patreon_flair\n",
    "            order by count(author_patreon_flair) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      body|   count|\n",
      "+----------+--------+\n",
      "| [removed]|19547496|\n",
      "| [deleted]|18453844|\n",
      "|         F|  581316|\n",
      "|       Yes|  266833|\n",
      "|   Thanks!|  230640|\n",
      "|         E|  222195|\n",
      "|         A|  216488|\n",
      "|Thank you!|  207593|\n",
      "|         I|  188876|\n",
      "|   Goodbye|  182330|\n",
      "|        No|  179680|\n",
      "|         O|  159118|\n",
      "|         S|  147105|\n",
      "|      Nice|  143063|\n",
      "|         N|  138271|\n",
      "|       Lol|  129636|\n",
      "|         T|  125267|\n",
      "|    Thanks|  124086|\n",
      "|         R|  120103|\n",
      "|         D|  107520|\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at body var\n",
    "\n",
    "spark.sql('''select body, count(body) as count \n",
    "             from sample group by body \n",
    "             order by count(body) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|can_mod_post|    count|\n",
      "+------------+---------+\n",
      "|       false|476259744|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at can mod post var\n",
    "\n",
    "spark.sql('''select can_mod_post, count(can_mod_post) as count \n",
    "            from sample group by can_mod_post order by count(can_mod_post) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|collapsed|    count|\n",
      "+---------+---------+\n",
      "|    false|451538199|\n",
      "|     true| 24721545|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at collapsed var\n",
    "\n",
    "spark.sql('''select collapsed, count(collapsed) as count \n",
    "            from sample group by collapsed order by count(collapsed) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|    collapsed_reason|  count|\n",
      "+--------------------+-------+\n",
      "|comment score bel...|6725928|\n",
      "|                null|      0|\n",
      "+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at collapsed reason var\n",
    "\n",
    "spark.sql('''select collapsed_reason, count(collapsed_reason) as count \n",
    "            from sample group by collapsed_reason order by count(collapsed_reason) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|controversiality|    count|\n",
      "+----------------+---------+\n",
      "|               0|465787145|\n",
      "|               1| 10472599|\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at controversiality var\n",
    "\n",
    "spark.sql('''select controversiality, count(controversiality) as count \n",
    "            from sample group by controversiality order by count(controversiality) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|can_gild|    count|\n",
      "+--------+---------+\n",
      "|    true|468695795|\n",
      "|   false|  7563949|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at can_gild var\n",
    "\n",
    "spark.sql('''select can_gild, count(can_gild) as count \n",
    "            from sample group by can_gild order by count(can_gild) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|gilded|    count|\n",
      "+------+---------+\n",
      "|     0|476161465|\n",
      "|     1|    92481|\n",
      "|     2|     4159|\n",
      "|     3|      954|\n",
      "|     4|      332|\n",
      "|     5|      136|\n",
      "|     6|       61|\n",
      "|     7|       46|\n",
      "|     8|       30|\n",
      "|    10|       21|\n",
      "|     9|       18|\n",
      "|    11|        7|\n",
      "|    12|        7|\n",
      "|    16|        6|\n",
      "|    13|        5|\n",
      "|    15|        3|\n",
      "|    14|        3|\n",
      "|    26|        2|\n",
      "|    17|        2|\n",
      "|    42|        1|\n",
      "+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at gilded var\n",
    "\n",
    "spark.sql('''select gilded, count(gilded) as count \n",
    "            from sample group by gilded order by count(gilded) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "| gildings|    count|\n",
      "+---------+---------+\n",
      "|[0, 0, 0]|476025207|\n",
      "|[1, 0, 0]|   123089|\n",
      "|[0, 1, 0]|    81310|\n",
      "|[1, 1, 0]|     7284|\n",
      "|[0, 0, 1]|     6208|\n",
      "|[2, 0, 0]|     5101|\n",
      "|[0, 2, 0]|     2147|\n",
      "|[2, 1, 0]|     1698|\n",
      "|[1, 2, 0]|      852|\n",
      "|[3, 0, 0]|      713|\n",
      "|[3, 1, 0]|      543|\n",
      "|[0, 1, 1]|      509|\n",
      "|[1, 0, 1]|      507|\n",
      "|[1, 1, 1]|      463|\n",
      "|[2, 2, 0]|      381|\n",
      "|[0, 3, 0]|      307|\n",
      "|[4, 0, 0]|      182|\n",
      "|[3, 2, 0]|      176|\n",
      "|[4, 1, 0]|      173|\n",
      "|[1, 3, 0]|      164|\n",
      "+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at gildings var\n",
    "\n",
    "spark.sql('''select gildings, count(gildings) as count \n",
    "            from sample group by gildings order by count(gildings) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|distinguished|  count|\n",
      "+-------------+-------+\n",
      "|    moderator|7567312|\n",
      "|        admin|   2718|\n",
      "|      special|      4|\n",
      "|         null|      0|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at distinguisehd var\n",
    "\n",
    "spark.sql('''select distinguished, count(distinguished) as count \n",
    "            from sample group by distinguished order by count(distinguished) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|     id|count|\n",
      "+-------+-----+\n",
      "|e6yvdxi|    1|\n",
      "|e6yvdzs|    1|\n",
      "|e6yveaq|    1|\n",
      "|e6yveem|    1|\n",
      "|e6yvefo|    1|\n",
      "|e6yvekc|    1|\n",
      "|e6yvenm|    1|\n",
      "|e6yvepu|    1|\n",
      "|e6yvewd|    1|\n",
      "|e6yvewf|    1|\n",
      "|e6yvezm|    1|\n",
      "|e6yvfbp|    1|\n",
      "|e6yvg8o|    1|\n",
      "|e6yvg9u|    1|\n",
      "|e6yvgst|    1|\n",
      "|e6yvgyd|    1|\n",
      "|e6yvhhj|    1|\n",
      "|e6yvibf|    1|\n",
      "|e6yviqb|    1|\n",
      "|e6yviun|    1|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at id var\n",
    "\n",
    "spark.sql('''select id, count(id) as count \n",
    "            from sample group by id order by count(id) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|  link_id| count|\n",
      "+---------+------+\n",
      "|t3_ai3l9x|102527|\n",
      "|t3_9uf0cp|100006|\n",
      "|t3_adp4lk|100002|\n",
      "|t3_a9mtop|100002|\n",
      "|t3_a4hj11|100001|\n",
      "|t3_a9mth7|100001|\n",
      "|t3_9zwdbb| 74325|\n",
      "|t3_a4fmf2| 69565|\n",
      "|t3_a9hhhr| 66620|\n",
      "|t3_ai1dc8| 59007|\n",
      "|t3_9ymxb8| 53311|\n",
      "|t3_9rg238| 49313|\n",
      "|t3_9rd4sk| 49106|\n",
      "|t3_ad7nkw| 47444|\n",
      "|t3_ahqwgf| 46797|\n",
      "|t3_ad9wlj| 46503|\n",
      "|t3_a9dat4| 45140|\n",
      "|t3_akx2l2| 44771|\n",
      "|t3_afnxmg| 44519|\n",
      "|t3_ad0did| 43901|\n",
      "+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at link_id var\n",
    "\n",
    "spark.sql('''select link_id, count(link_id) as count \n",
    "            from sample group by link_id order by count(link_id) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+\n",
      "|is_submitter|    count|\n",
      "+------------+---------+\n",
      "|       false|433767387|\n",
      "|        true| 42492357|\n",
      "+------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at is submitter var\n",
    "\n",
    "spark.sql('''select is_submitter, count(is_submitter) as count \n",
    "            from sample group by is_submitter order by count(is_submitter) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|no_follow|    count|\n",
      "+---------+---------+\n",
      "|     true|369890109|\n",
      "|    false|106369635|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at no follow var\n",
    "\n",
    "spark.sql('''select no_follow, count(no_follow) as count \n",
    "            from sample group by no_follow order by count(no_follow) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|removal_reason|count|\n",
      "+--------------+-----+\n",
      "|         legal| 1519|\n",
      "|          null|    0|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at removal reason var\n",
    "\n",
    "spark.sql('''select removal_reason, count(removal_reason) as count \n",
    "            from sample group by removal_reason order by count(removal_reason) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|stickied|    count|\n",
      "+--------+---------+\n",
      "|   false|473620848|\n",
      "|    true|  2638896|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at stickied var\n",
    "\n",
    "spark.sql('''select stickied, count(stickied) as count \n",
    "            from sample group by stickied order by count(stickied) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|    edited|    count|\n",
      "+----------+---------+\n",
      "|     false|463050980|\n",
      "|1545193908|       27|\n",
      "|1542125657|       26|\n",
      "|1540227757|       26|\n",
      "|1541170706|       26|\n",
      "|1540366106|       25|\n",
      "|1540366175|       25|\n",
      "|1541683238|       25|\n",
      "|1550267608|       25|\n",
      "|1550267605|       25|\n",
      "|1542125639|       25|\n",
      "|1540227769|       25|\n",
      "|1540366129|       25|\n",
      "|1550267612|       25|\n",
      "|1540366274|       25|\n",
      "|1550267615|       25|\n",
      "|1540366043|       24|\n",
      "|1540366228|       24|\n",
      "|1542125648|       24|\n",
      "|1545979255|       24|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at edited var\n",
    "\n",
    "spark.sql('''select edited, count(edited) as count \n",
    "            from sample group by edited order by count(edited) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|score|    count|\n",
      "+-----+---------+\n",
      "|    1|188310177|\n",
      "|    2| 79913414|\n",
      "|    3| 42554866|\n",
      "|    4| 18252997|\n",
      "|    5| 17166466|\n",
      "|    0| 16572699|\n",
      "|    6| 12795999|\n",
      "|    7|  9757851|\n",
      "|    8|  7689139|\n",
      "|    9|  6191938|\n",
      "|   -1|  5577580|\n",
      "|   10|  5086501|\n",
      "|   11|  4268134|\n",
      "|   12|  3646655|\n",
      "|   13|  3154503|\n",
      "|   -2|  3036632|\n",
      "|   14|  2757642|\n",
      "|   15|  2433514|\n",
      "|   16|  2167067|\n",
      "|   17|  1936937|\n",
      "+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at score var\n",
    "\n",
    "spark.sql('''select score, count(score) as count \n",
    "            from sample group by score order by count(score) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+\n",
      "|        subreddit|   count|\n",
      "+-----------------+--------+\n",
      "|        AskReddit|24422497|\n",
      "|         politics| 8977848|\n",
      "|              nfl| 5577430|\n",
      "|            funny| 4280825|\n",
      "|              nba| 4121533|\n",
      "|       The_Donald| 3950257|\n",
      "|        worldnews| 3452428|\n",
      "|              CFB| 3225713|\n",
      "|           gaming| 3189548|\n",
      "|       FortNiteBR| 3082335|\n",
      "|        dankmemes| 3039592|\n",
      "|         AskOuija| 3005982|\n",
      "|             news| 2881375|\n",
      "|             pics| 2787358|\n",
      "|            memes| 2598084|\n",
      "|           soccer| 2493694|\n",
      "|  leagueoflegends| 2459457|\n",
      "|   Showerthoughts| 2315785|\n",
      "|reddeadredemption| 2294151|\n",
      "| unpopularopinion| 2249675|\n",
      "+-----------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at subreddit var\n",
    "\n",
    "spark.sql('''select subreddit, count(subreddit) as count \n",
    "            from sample group by subreddit order by count(subreddit) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "| subreddit_type|    count|\n",
      "+---------------+---------+\n",
      "|         public|463303117|\n",
      "|     restricted| 12235122|\n",
      "|           user|   721502|\n",
      "|gold_restricted|        3|\n",
      "+---------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Looking at subreddit type var\n",
    "\n",
    "spark.sql('''select subreddit_type, count(subreddit_type) as count \n",
    "            from sample group by subreddit_type order by count(subreddit_type) desc''').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dataframe for use and creating new columns\n",
    "\n",
    "data = spark.sql('''select author, author_cakeday, body, author_patreon_flair,\n",
    "                        can_gild, controversiality, collapsed, score, subreddit,\n",
    "                        case when split(parent_id, '_')[0] = \"t1\" then 1 else 0 end as comment,\n",
    "                        case when split(parent_id, '_')[0] = \"t3\" then 1 else 0 end as post,\n",
    "                        case when distinguished = 'moderator' then 1 else 0 end as moderator,\n",
    "                        case when distinguished = 'admin' then 1 else 0 end as admin\n",
    "                        from sample \n",
    "                        where body <> '[removed]' and body <> '[deleted]'\n",
    "                        and body <> ''\n",
    "                        \n",
    "                    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting sample of data\n",
    "\n",
    "data = data.sample(False, .1, seed = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43831239"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing to file for later use\n",
    "data.write.parquet('s3://ppol567lab2/datasample.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
