{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-65-77.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"final_model\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(\"s3://ppol567lab2/data_text.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_cakeday: boolean (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- author_patreon_flair: boolean (nullable = true)\n",
      " |-- can_gild: boolean (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- collapsed: boolean (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- comment: integer (nullable = true)\n",
      " |-- post: integer (nullable = true)\n",
      " |-- moderator: integer (nullable = true)\n",
      " |-- admin: integer (nullable = true)\n",
      " |-- body_clean: string (nullable = true)\n",
      " |-- body_tokenized: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- body_no_stopw: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawfeatures: vector (nullable = true)\n",
      " |-- feats: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#assembling vector to run LR \n",
    "vectorAssembler = VectorAssembler(inputCols = ['score',\n",
    "                                              'collapsed', 'moderator', 'feats', 'comment',], \n",
    "                                  outputCol = 'features')\n",
    "\n",
    "model_df = vectorAssembler.transform(data)\n",
    "model_df = model_df.select('features', 'controversiality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into training and test\n",
    "training, test = model_df.randomSplit([0.6, 0.4], 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26297781"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#running first model\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'controversiality', maxIter=10)\n",
    "lr_model = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving output for later use\n",
    "lr_model.save(\"s3://ppol567lab2/lr_model.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+--------------------+--------------------+----------+\n",
      "|           features|controversiality|       rawPrediction|         probability|prediction|\n",
      "+-------------------+----------------+--------------------+--------------------+----------+\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               0|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               1|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|     (262148,[],[])|               1|[3.84760059684005...|[0.97911464607619...|       0.0|\n",
      "|(262148,[0],[-3.0])|               0|[3.84593397713605...|[0.97908053788245...|       0.0|\n",
      "|(262148,[0],[-2.0])|               1|[3.84648951703738...|[0.97909191333298...|       0.0|\n",
      "|(262148,[0],[-1.0])|               0|[3.84704505693871...|[0.97910328272987...|       0.0|\n",
      "|(262148,[0],[-1.0])|               0|[3.84704505693871...|[0.97910328272987...|       0.0|\n",
      "|(262148,[0],[-1.0])|               0|[3.84704505693871...|[0.97910328272987...|       0.0|\n",
      "|(262148,[0],[-1.0])|               0|[3.84704505693871...|[0.97910328272987...|       0.0|\n",
      "|(262148,[0],[-1.0])|               1|[3.84704505693871...|[0.97910328272987...|       0.0|\n",
      "|(262148,[0],[-1.0])|               1|[3.84704505693871...|[0.97910328272987...|       0.0|\n",
      "| (262148,[0],[1.0])|               0|[3.84815613674138...|[0.97912600337501...|       0.0|\n",
      "+-------------------+----------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels = predictions.select(['prediction','controversiality'])\n",
    "\n",
    "preds_and_labels = preds_and_labels.withColumn(\"prediction\",preds_and_labels.prediction.cast('float'))\n",
    "preds_and_labels = preds_and_labels.withColumn(\"controversiality\",preds_and_labels.controversiality.cast('float'))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(preds_and_labels.rdd.map(tuple))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.501353127128873\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing column from boolean to int\n",
    "data = data.withColumn(\"author_patreon_flair\",data.author_patreon_flair.cast('int'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size\n",
    "\n",
    "#creating body length column\n",
    "data = data.withColumn('body_length', size(data.body_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#assembling new vector\n",
    "vectorAssembler = VectorAssembler(inputCols = ['score', 'body_length',\n",
    "                                              'collapsed', 'moderator', 'feats', 'comment', 'author_patreon_flair'], \n",
    "                                  outputCol = 'features')\n",
    "\n",
    "model_df2 = vectorAssembler.transform(data)\n",
    "model_df2 = model_df2.select('features', 'controversiality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, test = model_df2.randomSplit([0.6, 0.4], 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#running new model\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'controversiality', maxIter=10)\n",
    "lr_model = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "#select only prediction and label columns\n",
    "preds_and_labels = predictions.select(['prediction','controversiality'])\n",
    "\n",
    "preds_and_labels = preds_and_labels.withColumn(\"prediction\",preds_and_labels.prediction.cast('float'))\n",
    "preds_and_labels = preds_and_labels.withColumn(\"controversiality\",preds_and_labels.controversiality.cast('float'))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(preds_and_labels.rdd.map(tuple))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.5116195465971471\n"
     ]
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
